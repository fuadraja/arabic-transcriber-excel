# app.py
import os
from io import BytesIO
from datetime import datetime
from typing import List, Dict, Any, Tuple
import tempfile

import streamlit as st
import pandas as pd

from openai import OpenAI
from openai import APIError, AuthenticationError, RateLimitError, BadRequestError

# ========================= Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© =========================
st.set_page_config(page_title="ØªÙØ±ÙŠØº Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© â†’ Ø¥ÙƒØ³Ù„", page_icon="ğŸ“", layout="wide")
st.title("ğŸ“ ØªÙØ±ÙŠØº Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ© (Ø¹Ø±Ø¨ÙŠ) â†’ Ø¥ÙƒØ³Ù„ + ØªØ­Ù„ÙŠÙ„ Ù†ØµÙŠ (Ø¨Ø¯ÙˆÙ† ØªØ­ÙˆÙŠÙ„ ØµÙŠØº)")

st.caption("Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØª Ø¨ØµÙŠØºØ© Ù…Ø¯Ø¹ÙˆÙ…Ø©ØŒ Ø£Ø¯Ø®ÙÙ„ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒÙ„ Ù…Ù„Ù (Ø¥Ù† Ø±ØºØ¨Øª)ØŒ Ø³Ù†ÙÙØ±Ù‘ÙØº Ø§Ù„Ù†Øµ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆÙ†ÙØ®Ø±Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ù…Ù„Ù Ø¥ÙƒØ³Ù„ ÙˆØ§Ø­Ø¯. ÙŠÙ…ÙƒÙ† Ø£ÙŠØ¶Ù‹Ø§ Ø¥Ø¬Ø±Ø§Ø¡ ØªØ­Ù„ÙŠÙ„ Ù†ØµÙŠ Ø§Ø®ØªÙŠØ§Ø±ÙŠ.")

# ========================= Ù…ÙØ§ØªÙŠØ­ ÙˆØ£Ù…Ø§Ù† =========================
OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY") if "OPENAI_API_KEY" in st.secrets else None

if not OPENAI_API_KEY:
    with st.expander("ğŸ” Ø£Ø¯Ø®ÙÙ„ Ù…ÙØªØ§Ø­ OpenAI API (Ù…Ø¤Ù‚Øª ÙÙŠ Ø¬Ù„Ø³ØªÙƒ ÙÙ‚Ø·)"):
        OPENAI_API_KEY = st.text_input(
            "OPENAI_API_KEY",
            type="password",
            placeholder="sk-********************************",
            help="Ù„Ø£ÙØ¶Ù„ Ø£Ù…Ø§Ù† Ø§Ø³ØªØ®Ø¯Ù… Settings â†’ Secrets Ø¹Ù„Ù‰ Streamlit Cloud.",
        )

if not OPENAI_API_KEY:
    st.info("Ù„Ù† ÙŠØ¹Ù…Ù„ Ø§Ù„ØªÙØ±ÙŠØº Ù‚Ø¨Ù„ Ø¥Ø¯Ø®Ø§Ù„ Ù…ÙØªØ§Ø­ OpenAI API.", icon="ğŸ”‘")

# ========================= Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ: Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª =========================
with st.sidebar:
    st.header("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")

    st.subheader("Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªÙØ±ÙŠØº")
    asr_model = st.selectbox(
        "Ø§Ø®ØªØ± Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªÙØ±ÙŠØº",
        options=["gpt-4o-transcribe", "whisper-1"],
        index=0,
        help="Ø¥Ù† Ù„Ù… ÙŠØªÙˆÙØ± Ø§Ù„Ø£ÙˆÙ„ ÙÙŠ Ø­Ø³Ø§Ø¨Ùƒ Ø¬Ø±Ù‘Ø¨ whisper-1."
    )
    asr_temperature = st.slider("Temperature (ØªÙØ±ÙŠØº)", 0.0, 1.0, 0.0, 0.1)

    st.subheader("Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙŠ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)")
    enable_nlp = st.checkbox("ØªÙØ¹ÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙŠ", value=True, help="Ù…Ù„Ø®Øµ + ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© + Ù…Ø´Ø§Ø¹Ø± + Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª.")
    nlp_model = st.selectbox("Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„", options=["gpt-4o-mini", "gpt-4o", "gpt-4.1-mini"], index=0)
    nlp_depth = st.select_slider("ØªÙØµÙŠÙ„ Ø§Ù„Ù…Ù„Ø®Øµ", options=["Ù‚ØµÙŠØ±", "Ù…ØªÙˆØ³Ø·", "Ù…ÙØµÙ„"], value="Ù…ØªÙˆØ³Ø·")

    st.subheader("ğŸ’° Ø­Ø§Ø³Ø¨Ø© Ø§Ù„ØªÙƒÙ„ÙØ© (ØªÙ‚Ø¯ÙŠØ±ÙŠ)")
    st.caption("ÙŠÙ…ÙƒÙ† ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø£Ø³Ø¹Ø§Ø± ÙŠØ¯ÙˆÙŠÙ‹Ø§ Ø­Ø³Ø¨ Ø®Ø·Ø© OpenAI Ù„Ø¯ÙŠÙƒ.")
    price_per_min_gpt4o_transcribe = st.number_input("Ø³Ø¹Ø±/Ø¯Ù‚ÙŠÙ‚Ø© - gpt-4o-transcribe ($)", value=0.006, min_value=0.0, step=0.001, format="%.3f")
    price_per_min_whisper = st.number_input("Ø³Ø¹Ø±/Ø¯Ù‚ÙŠÙ‚Ø© - whisper-1 ($)", value=0.006, min_value=0.0, step=0.001, format="%.3f")
    price_per_1k_tokens_nlp = st.number_input("Ø³Ø¹Ø±/1000 ØªÙˆÙƒÙ† Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠ ($)", value=0.002, min_value=0.0, step=0.001, format="%.3f")
    st.caption("Ù…Ù„Ø§Ø­Ø¸Ø©: Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ù‡Ù†Ø§ Ø§ÙØªØ±Ø§Ø¶ÙŠØ© ÙˆÙ‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¹Ø¯ÙŠÙ„ Ù„ØªØ·Ø§Ø¨Ù‚ Ø­Ø³Ø§Ø¨Ùƒ.")

# ========================= Ø£Ø¯ÙˆØ§Øª Ù…Ø³Ø§Ø¹Ø¯Ø© =========================
SUPPORTED_AUDIO = ['flac', 'm4a', 'mp3', 'mp4', 'mpeg', 'mpga', 'oga', 'ogg', 'wav', 'webm']

def _get_file_ext(name: str) -> str:
    return (os.path.splitext(name)[1][1:] or "").lower()

def _safe_duration_seconds(file_name: str, data: bytes) -> float:
    """
    ÙŠØ­Ø§ÙˆÙ„ Ù‚Ø±Ø§Ø¡Ø© Ù…Ø¯Ø© Ø§Ù„ØµÙˆØª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… mutagen (Ø¨Ø¯ÙˆÙ† FFmpeg).
    Ø¥Ù† ÙØ´Ù„ Ù„Ø³Ø¨Ø¨ Ù…Ø§ØŒ ÙŠØ¹ÙŠØ¯ -1.
    """
    try:
        from mutagen import File as MutagenFile
        with tempfile.NamedTemporaryFile(delete=True, suffix=f"_{os.path.basename(file_name)}") as tmp:
            tmp.write(data)
            tmp.flush()
            audio = MutagenFile(tmp.name)
            if audio is not None and getattr(audio, "info", None) and getattr(audio.info, "length", None):
                return float(audio.info.length)
        return -1.0
    except Exception:
        return -1.0

def transcribe_bytes(client: OpenAI, name: str, content_bytes: bytes, ext: str, language="ar", temperature=0.0) -> str:
    """
    ÙŠØ±Ø³Ù„ Ø§Ù„Ù…Ù„Ù Ø¥Ù„Ù‰ ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªÙØ±ÙŠØº ÙˆÙŠÙØ¹ÙŠØ¯ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ.
    """
    try:
        resp = client.audio.transcriptions.create(
            model=asr_model,
            file=(f"{os.path.splitext(name)[0]}.{ext}", content_bytes),
            language=language,
            temperature=temperature,
            response_format="text",
        )
        if isinstance(resp, str):
            return resp.strip()
        return getattr(resp, "text", "").strip()
    except AuthenticationError as e:
        raise RuntimeError("ÙØ´Ù„ Ø§Ù„ØªÙˆØ«ÙŠÙ‚: ØªØ­Ù‚Ù‘Ù‚ Ù…Ù† Ù…ÙØªØ§Ø­ OpenAI API.") from e
    except RateLimitError as e:
        raise RuntimeError("ØªØ¬Ø§ÙˆØ²Øª Ø§Ù„Ø­ØµØ©/Ø§Ù„Ù…Ø¹Ø¯Ù„. Ø±Ø§Ø¬Ø¹ Ø®Ø·ØªÙƒ Ø£Ùˆ Ø£Ø¹Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ù‹Ø§.") from e
    except BadRequestError as e:
        raise RuntimeError(f"Ø·Ù„Ø¨ ØºÙŠØ± ØµØ§Ù„Ø­: {e}") from e
    except APIError as e:
        raise RuntimeError(f"Ø®Ø·Ø£ Ù…Ù† Ø®Ø§Ø¯Ù… OpenAI: {e}") from e
    except Exception as e:
        raise RuntimeError(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙØ±ÙŠØº: {e}") from e

def analyze_text(client: OpenAI, text: str, depth: str) -> Dict[str, Any]:
    """
    ØªØ­Ù„ÙŠÙ„ Ù†ØµÙŠ Ø¨Ø³ÙŠØ·:
    - Ù…Ù„Ø®Øµ (Ø­Ø³Ø¨ Ø§Ù„Ø¹Ù…Ù‚)
    - ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ©
    - Ù…Ø´Ø§Ø¹Ø± Ø¹Ø§Ù…Ø©
    - Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª
    """
    wc = len(text.split())
    if not text.strip():
        return {"Ù…Ù„Ø®Øµ": "", "ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ©": "", "Ø§Ù„Ù…Ø´Ø§Ø¹Ø±": "", "Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª": 0}

    prompt = f"""Ø­Ù„Ù‘Ù„ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ø¥ÙŠØ¬Ø§Ø² ÙˆÙˆØ¶ÙˆØ­:
- Ù‚Ø¯Ù‘Ù… Ù…Ù„Ø®ØµÙ‹Ø§ ({depth}) Ù…Ù† 3-6 Ø¬Ù…Ù„ Ø¨Ø­Ø³Ø¨ Ø§Ù„Ø¹Ù…Ù‚.
- Ø§Ø³ØªØ®Ø±Ø¬ Ø­ØªÙ‰ 8 ÙƒÙ„Ù…Ø§Øª/Ø¹Ø¨Ø§Ø±Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© (comma-separated).
- Ù‚ÙŠÙ‘Ù… Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø¹Ø§Ù…Ø© (Ø¥ÙŠØ¬Ø§Ø¨ÙŠ/Ù…Ø­Ø§ÙŠØ¯/Ø³Ù„Ø¨ÙŠ) Ù…Ø¹ Ø¬Ù…Ù„Ø© ØªÙØ³ÙŠØ±ÙŠØ© Ù‚ØµÙŠØ±Ø©.
Ø£Ø¹Ø¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨ØµÙŠØºØ© JSON Ø¨Ø§Ù„Ù…ÙØ§ØªÙŠØ­: summary, keywords, sentiment.
Ø§Ù„Ù†Øµ:
{text}"""

    try:
        comp = client.chat.completions.create(
            model=nlp_model,
            messages=[
                {"role": "system", "content": "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø®Ø¨ÙŠØ± ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.2,
        )
        raw = comp.choices[0].message.content.strip()
        import json, re
        match = re.search(r'\{.*\}', raw, re.S)
        data = {}
        if match:
            data = json.loads(match.group(0))
        else:
            data = {"summary": raw, "keywords": "", "sentiment": ""}

        return {
            "Ù…Ù„Ø®Øµ": data.get("summary", ""),
            "ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ©": data.get("keywords", ""),
            "Ø§Ù„Ù…Ø´Ø§Ø¹Ø±": data.get("sentiment", ""),
            "Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª": wc,
        }
    except Exception:
        return {"Ù…Ù„Ø®Øµ": "", "ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ©": "", "Ø§Ù„Ù…Ø´Ø§Ø¹Ø±": "", "Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª": wc}

def minutes_from_seconds(sec: float) -> float:
    return max(0.0, round(sec / 60.0, 2)) if sec and sec > 0 else 0.0

# ========================= Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„: Ø§Ù„Ù…Ù„ÙØ§Øª + Ø¨ÙŠØ§Ù†Ø§Øª Ù„ÙƒÙ„ Ù…Ù„Ù =========================
with st.form("upload_form", clear_on_submit=False):
    st.subheader("ğŸ“¥ Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª")
    uploaded_files = st.file_uploader(
        "Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØª (ÙŠØ¯Ø¹Ù…: " + ", ".join(SUPPORTED_AUDIO) + ")",
        type=SUPPORTED_AUDIO,
        accept_multiple_files=True
    )

    st.markdown("â€”")
    st.subheader("ğŸ§¾ Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ø§Ù…Ø© (ØªÙØ³ØªØ®Ø¯Ù… Ø§ÙØªØ±Ø§Ø¶ÙŠÙ‹Ø§ Ù„ÙƒÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª)")
    c1, c2, c3 = st.columns(3)
    with c1:
        default_company = st.text_input("Ø§Ø³Ù… Ø§Ù„Ø´Ø±ÙƒØ© (Ø§ÙØªØ±Ø§Ø¶ÙŠ)")
        default_employee = st.text_input("Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ¸Ù (Ø§ÙØªØ±Ø§Ø¶ÙŠ)")
    with c2:
        default_job = st.text_input("Ø§Ù„ÙˆØ¸ÙŠÙØ© (Ø§ÙØªØ±Ø§Ø¶ÙŠ)")
        default_exp = st.text_input("Ø§Ù„Ø®Ø¨Ø±Ø© (Ø§ÙØªØ±Ø§Ø¶ÙŠ)", placeholder="Ù…Ø«Ø§Ù„: 5 Ø³Ù†ÙˆØ§Øª")
    with c3:
        default_spec = st.text_input("Ø§Ù„Ø§Ø®ØªØµØ§Øµ (Ø§ÙØªØ±Ø§Ø¶ÙŠ)")
        per_file_overrides = st.checkbox("Ø³Ø£Ø¯Ø®Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø®ØªÙ„ÙØ© Ù„ÙƒÙ„ Ù…Ù„Ù", value=True)

    per_file_meta: List[Dict[str, str]] = []
    if uploaded_files and per_file_overrides:
        st.markdown("â€”")
        st.subheader("âœï¸ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø®ØµÙ‘ØµØ© Ù„ÙƒÙ„ Ù…Ù„Ù")
        for idx, f in enumerate(uploaded_files, start=1):
            with st.expander(f"Ø§Ù„Ù…Ù„Ù #{idx}: {f.name}", expanded=False):
                col1, col2, col3 = st.columns(3)
                with col1:
                    comp = st.text_input(f"Ø§Ø³Ù… Ø§Ù„Ø´Ø±ÙƒØ© #{idx}", key=f"company_{idx}", value=default_company)
                    emp = st.text_input(f"Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ¸Ù #{idx}", key=f"employee_{idx}", value=default_employee)
                with col2:
                    job = st.text_input(f"Ø§Ù„ÙˆØ¸ÙŠÙØ© #{idx}", key=f"job_{idx}", value=default_job)
                    exp = st.text_input(f"Ø§Ù„Ø®Ø¨Ø±Ø© #{idx}", key=f"exp_{idx}", value=default_exp)
                with col3:
                    spec = st.text_input(f"Ø§Ù„Ø§Ø®ØªØµØ§Øµ #{idx}", key=f"spec_{idx}", value=default_spec)
                per_file_meta.append({
                    "Ø§Ø³Ù… Ø§Ù„Ø´Ø±ÙƒØ©": comp, "Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ¸Ù": emp, "Ø§Ù„ÙˆØ¸ÙŠÙØ©": job, "Ø§Ù„Ø®Ø¨Ø±Ø©": exp, "Ø§Ù„Ø§Ø®ØªØµØ§Øµ": spec
                })

    submit = st.form_submit_button("â–¶ï¸ Ø¨Ø¯Ø¡ Ø§Ù„ØªÙØ±ÙŠØº")

# ========================= Ø§Ù„ØªÙ†ÙÙŠØ° =========================
if submit:
    if not OPENAI_API_KEY:
        st.error("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ù…ÙØªØ§Ø­ OpenAI API Ø£ÙˆÙ„Ù‹Ø§.", icon="ğŸš«")
        st.stop()

    if not uploaded_files:
        st.warning("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø±ÙØ¹ Ù…Ù„Ù ØµÙˆØªÙŠ ÙˆØ§Ø­Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„.", icon="ğŸ“")
        st.stop()

    # ØªØ­Ù‚Ù‘Ù‚ Ù…Ø¨ÙƒØ± Ù…Ù† Ø§Ù„Ø§Ù…ØªØ¯Ø§Ø¯Ø§Øª
    bad_files = [f.name for f in uploaded_files if _get_file_ext(f.name) not in SUPPORTED_AUDIO]
    if bad_files:
        st.error(
            "Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù„ÙØ§Øª ØºÙŠØ± Ø¨ØµÙŠØºØ© Ù…Ø¯Ø¹ÙˆÙ…Ø©ØŒ Ø§Ù„Ø±Ø¬Ø§Ø¡ ØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø®Ø§Ø±Ø¬ÙŠÙ‹Ø§ Ø¥Ù„Ù‰ ØµÙŠØºØ© Ù…Ø¯Ø¹ÙˆÙ…Ø© Ø«Ù… Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø±ÙØ¹:\n- " + "\n- ".join(bad_files),
            icon="ğŸš«"
        )
        st.stop()

    client = OpenAI(api_key=OPENAI_API_KEY)

    results_rows: List[Dict[str, Any]] = []
    durations_min: List[float] = []

    progress = st.progress(0)
    status = st.empty()

    for i, f in enumerate(uploaded_files, start=1):
        status.info(f"Ø¬Ø§Ø±Ù Ù…Ø¹Ø§Ù„Ø¬Ø©: {f.name} ...")

        # Ø¨ÙŠØ§Ù†Ø§Øª Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù
        if per_file_overrides and len(per_file_meta) >= i:
            meta = per_file_meta[i-1]
        else:
            meta = {
                "Ø§Ø³Ù… Ø§Ù„Ø´Ø±ÙƒØ©": default_company,
                "Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ¸Ù": default_employee,
                "Ø§Ù„ÙˆØ¸ÙŠÙØ©": default_job,
                "Ø§Ù„Ø®Ø¨Ø±Ø©": default_exp,
                "Ø§Ù„Ø§Ø®ØªØµØ§Øµ": default_spec,
            }

        # Ø§Ù‚Ø±Ø£ Ø§Ù„Ø¨Ø§ÙŠØªØ§Øª ÙˆØ§Ø­Ø³Ø¨ Ù…Ø¯Ø© ØªÙ‚Ø±ÙŠØ¨ÙŠØ©
        ext = _get_file_ext(f.name)
        fbytes = f.read()
        f.seek(0)
        duration_sec = _safe_duration_seconds(f.name, fbytes)

        # Ø§Ù„ØªÙØ±ÙŠØº
        try:
            text = transcribe_bytes(client, f.name, fbytes, ext, language="ar", temperature=asr_temperature)
        except Exception as e:
            text = f"Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙØ±ÙŠØº: {e}"

        row = {**meta, "Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø© (Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙØ±Øº)": text or ""}

        # Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙŠ
        if enable_nlp and text and not str(text).startswith("Ø®Ø·Ø£"):
            analysis = analyze_text(client, text, depth=nlp_depth)
            row.update(analysis)
        elif enable_nlp:
            row.update({"Ù…Ù„Ø®Øµ": "", "ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ©": "", "Ø§Ù„Ù…Ø´Ø§Ø¹Ø±": "", "Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª": 0})

        results_rows.append(row)
        durations_min.append(minutes_from_seconds(duration_sec))
        progress.progress(i / len(uploaded_files))

    status.success("Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªÙØ±ÙŠØº âœ…")

    # ========================= Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ + Ø§Ù„ØªØ­Ù…ÙŠÙ„ =========================
    st.subheader("ğŸ“„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
    cols = ["Ø§Ø³Ù… Ø§Ù„Ø´Ø±ÙƒØ©", "Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ¸Ù", "Ø§Ù„ÙˆØ¸ÙŠÙØ©", "Ø§Ù„Ø®Ø¨Ø±Ø©", "Ø§Ù„Ø§Ø®ØªØµØ§Øµ", "Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø© (Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙØ±Øº)"]
    if enable_nlp:
        cols += ["Ù…Ù„Ø®Øµ", "ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ©", "Ø§Ù„Ù…Ø´Ø§Ø¹Ø±", "Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª"]

    df = pd.DataFrame(results_rows, columns=cols)
    st.dataframe(df, use_container_width=True, height=420)

    # Excel
    excel_buffer = BytesIO()
    with pd.ExcelWriter(excel_buffer, engine="openpyxl") as writer:
        df.to_excel(writer, index=False, sheet_name="Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
    excel_buffer.seek(0)

    now = datetime.now().strftime("%Y%m%d_%H%M%S")
    excel_name = f"ØªÙØ±ÙŠØº_Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø§Øª_{now}.xlsx"

    cdl, cdr = st.columns(2)
    with cdl:
        st.download_button(
            label="â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ø¥ÙƒØ³Ù„",
            data=excel_buffer,
            file_name=excel_name,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
    with cdr:
        csv_data = df.to_csv(index=False).encode("utf-8-sig")
        st.download_button(
            label="â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ CSV (UTF-8)",
            data=csv_data,
            file_name=f"ØªÙØ±ÙŠØº_Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø§Øª_{now}.csv",
            mime="text/csv"
        )

    # ========================= Ø­Ø§Ø³Ø¨Ø© Ø§Ù„ØªÙƒÙ„ÙØ© =========================
    st.subheader("ğŸ’° ØªÙ‚Ø¯ÙŠØ± Ø§Ù„ØªÙƒÙ„ÙØ©")
    total_minutes = round(sum(durations_min), 2)
    st.caption("Ø¥Ù† ØªØ¹Ø°Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¯Ø© Ù…Ù† Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ù„ÙØ§Øª Ø³ØªÙƒÙˆÙ† Ø§Ù„Ø¯Ù‚Ø§Ø¦Ù‚ 0 Ù„Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù†Ø§ØµØ±.")

    if asr_model == "gpt-4o-transcribe":
        asr_cost = total_minutes * float(price_per_min_gpt4o_transcribe)
    else:
        asr_cost = total_minutes * float(price_per_min_whisper)

    total_words = 0
    if enable_nlp:
        try:
            total_words = int(df["Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª"].fillna(0).sum())
        except Exception:
            total_words = 0
    est_tokens_nlp = int((total_words * 5) / 4)  # ØªÙ‚Ø¯ÙŠØ± Ø¨Ø³ÙŠØ·
    nlp_cost = (est_tokens_nlp / 1000.0) * float(price_per_1k_tokens_nlp) if enable_nlp else 0.0

    st.write(f"- **Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¯Ù‚Ø§Ø¦Ù‚:** ~ {total_minutes} Ø¯Ù‚ÙŠÙ‚Ø©")
    st.write(f"- **ØªÙƒÙ„ÙØ© Ø§Ù„ØªÙØ±ÙŠØº (ASR):** ~ ${asr_cost:.4f}")
    if enable_nlp:
        st.write(f"- **ØªÙ‚Ø¯ÙŠØ± ØªÙˆÙƒÙ†Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„:** ~ {est_tokens_nlp} ØªÙˆÙƒÙ†")
        st.write(f"- **ØªÙƒÙ„ÙØ© Ø§Ù„ØªØ­Ù„ÙŠÙ„ (NLP):** ~ ${nlp_cost:.4f}")
    st.markdown(f"**Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªÙ‚Ø¯ÙŠØ±ÙŠ:** ~ ${asr_cost + nlp_cost:.4f}")

# ========================= Ù…Ù„Ø§Ø­Ø¸Ø§Øª =========================
with st.expander("ğŸ’¡ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù‡Ø§Ù…Ø©"):
    st.markdown(
        """
- ÙŠØ¯Ø¹Ù… Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ØµÙŠØº Ø§Ù„ØµÙˆØª: `flac, m4a, mp3, mp4, mpeg, mpga, oga, ogg, wav, webm`.
- Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªØ­ÙˆÙŠÙ„ ØµÙŠØº Ø¯Ø§Ø®Ù„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ù„ØªØ¬Ù†Ù‘Ø¨ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø¨Ù†Ø§Ø¡ Ø¹Ù„Ù‰ Streamlit Cloud.
- Ù„Ùˆ Ø¸Ù‡Ø±Øª Ø£Ø®Ø·Ø§Ø¡ **401** ØªØ£ÙƒÙ‘Ø¯ Ù…Ù† Ù…ÙØªØ§Ø­ OpenAI. Ù„Ùˆ **429** (Ø­ØµØ©/Ù…Ø¹Ø¯Ù„) Ø±Ø§Ø¬Ø¹ Ø§Ù„ÙÙˆØªØ±Ø© Ø£Ùˆ Ø£Ø¹Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©.
- Ø§Ù„Ø£Ø³Ø¹Ø§Ø± ÙÙŠ Ø§Ù„Ø­Ø§Ø³Ø¨Ø© **ØªÙ‚Ø¯ÙŠØ±ÙŠØ©** ÙˆÙŠÙ…ÙƒÙ† ØªØ¹Ø¯ÙŠÙ„Ù‡Ø§ Ù…Ù† Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ.
- Ù„Ø§ ØªØ­ÙØ¸ Ù…ÙØªØ§Ø­Ùƒ Ø¯Ø§Ø®Ù„ Ø§Ù„ÙƒÙˆØ¯ Ø£Ùˆ GitHub. Ø§Ø³ØªØ®Ø¯Ù… **Secrets** Ø¹Ù„Ù‰ Streamlit Cloud Ø£Ùˆ Ø§Ù„Ø­Ù‚Ù„ Ø§Ù„Ù…Ø¤Ù‚Øª.
        """
    )
