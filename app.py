import streamlit as st
import pandas as pd
from io import BytesIO
from datetime import datetime
import math
import json
from openai import OpenAI

# ====================== ุฅุนุฏุงุฏุงุช ุงูุตูุญุฉ ======================
st.set_page_config(page_title="ุชูุฑูุบ + ุชุญููู ุงูููุงุจูุงุช", page_icon="๐", layout="wide")
st.title("๐ ุชูุฑูุบ ุงูููุงุจูุงุช ุงูุตูุชูุฉ (ุนุฑุจู) + ุชุญููู ูุตู ุชููุงุฆู โ ุฅูุณู")

st.caption("ุงุฑูุน ุนุฏุฉ ูููุงุช ุตูุชูุฉ ุจุงูุนุฑุจูุฉุ ุฃุฏุฎู ุจูุงูุงุช ูู ูููุ ุณููุฑูุบ ุงููุต ููุญูููู ุชููุงุฆููุง ููุตุฏุฑ ุงููุชุงุฆุฌ ุฅูู ููู ุฅูุณู ูุงุญุฏ.")

# ====================== ููุชุงุญ OpenAI ======================
OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY") if "OPENAI_API_KEY" in st.secrets else None
if not OPENAI_API_KEY:
    with st.expander("๐ ุฃุฏุฎู OpenAI API Key (ูุคูุช ููุฐู ุงูุฌูุณุฉ ุฅู ูู ุชุณุชุทุน ุงุณุชุฎุฏุงู Secrets)"):
        OPENAI_API_KEY = st.text_input("OPENAI_API_KEY", type="password", placeholder="sk-********************************")
if not OPENAI_API_KEY:
    st.info("ููุถู ุฅุถุงูุฉ ุงูููุชุงุญ ูู Settings โ Secrets ุนูู Streamlit Cloud.", icon="๐")

# ====================== ุงูุดุฑูุท ุงูุฌุงูุจู: ุฅุนุฏุงุฏุงุช + ุญุงุณุจุฉ ุชูููุฉ ======================
with st.sidebar:
    st.header("โ๏ธ ุงูุฅุนุฏุงุฏุงุช")

    trx_model = st.selectbox(
        "ูููุฐุฌ ุงูุชูุฑูุบ ุงูุตูุชู",
        options=["whisper-1", "gpt-4o-transcribe"],  # ุฌุฑูุจ whisper-1 ุฃููุงู
        index=0,
        help="ุฅู ูู ูุนูู gpt-4o-transcribe ุนูู ุญุณุงุจู ุงุณุชุฎุฏู whisper-1."
    )
    nlp_model = st.selectbox(
        "ูููุฐุฌ ุงูุชุญููู ุงููุตู",
        options=["gpt-4o-mini", "gpt-4o-mini-translate"],  # ููุงููุง ุงูุชุตุงุฏู
        index=0,
        help="ูููุฐุฌ ุงูุชุตุงุฏู ูุงุณุชุฎุฑุงุฌ ุงูููุฎุต/ุงูููุงุฑุงุช/ุงููุดุงุนุฑ."
    )
    temperature = st.slider("Temperature (ููุชุญููู ููุท)", 0.0, 1.0, 0.0, 0.1)

    st.divider()
    st.subheader("๐ฐ ุญุงุณุจุฉ ุงูุชูููุฉ ุงูุชูุฏูุฑูุฉ")

    # ุฃุณุนุงุฑ ุชูุฑูุจูุฉ (ููุง ูุงูุดูุง)
    WHISPER_PER_MIN = 0.006  # $/minute
    GPT_INPUT_PER_1K = 0.00015
    GPT_OUTPUT_PER_1K = 0.00060

    calc_files = st.number_input("ุนุฏุฏ ุงููููุงุช", min_value=1, value=10, step=1)
    calc_avg_minutes = st.number_input("ูุชูุณุท ุงูุฏูุงุฆู ููู ููู", min_value=0.0, value=10.0, step=1.0)
    calc_avg_tokens_in = st.number_input("ูุชูุณุท Tokens ูููุต/ููู (ุงุฎุชูุงุฑู)", min_value=0, value=2000, step=500,
                                         help="ุฅู ุชุฑูุชู ููุง ูู ุณูุณุชุฎุฏู 2K ููุชูุณุท.")
    calc_avg_tokens_out = st.number_input("ูุชูุณุท Tokens ูููุฎุฑุฌุงุช/ููู (ุงุฎุชูุงุฑู)", min_value=0, value=500, step=100)

    est_trx_cost = calc_files * calc_avg_minutes * WHISPER_PER_MIN
    est_nlp_cost = calc_files * ((calc_avg_tokens_in / 1000) * GPT_INPUT_PER_1K + (calc_avg_tokens_out / 1000) * GPT_OUTPUT_PER_1K)
    st.metric("ุชูููุฉ ุงูุชูุฑูุบ (ุชูุฏูุฑู)", f"${est_trx_cost:,.2f}")
    st.metric("ุชูููุฉ ุงูุชุญููู (ุชูุฏูุฑู)", f"${est_nlp_cost:,.2f}")
    st.metric("ุงูุฅุฌูุงูู (ุชูุฏูุฑู)", f"${(est_trx_cost + est_nlp_cost):,.2f}")

# ====================== ุฑูุน ุงููููุงุช + ุฌุฏูู ุจูุงูุงุช ููู ููู ======================
st.subheader("๐ค ุฑูุน ุงููููุงุช ูุฅุฏุฎุงู ุจูุงูุงุช ูู ููู")
uploaded_files = st.file_uploader(
    "ุงุฑูุน ูููุงุช ุงูุตูุช (MP3/WAV/M4A/MP4). ูููู ุงุฎุชูุงุฑ ุฃูุซุฑ ูู ููู",
    type=["mp3", "wav", "m4a", "mp4"],
    accept_multiple_files=True
)

# ูุจูู ุฌุฏูู ุจูุงูุงุช ูุงุจู ููุชุนุฏูู ูุฅุฏุฎุงู ุงูุจูุงูุงุช ููู ููู
file_rows = []
if uploaded_files:
    for idx, f in enumerate(uploaded_files, start=1):
        file_rows.append({
            "index": idx,
            "ุงุณู ุงูููู": f.name,
            "ุงุณู ุงูุดุฑูุฉ": "",
            "ุงุณู ุงูููุธู": "",
            "ุงููุธููุฉ": "",
            "ุงูุฎุจุฑุฉ": "",
            "ุงูุงุฎุชุตุงุต": "",
            "ุงููุฏุฉ (ุฏูููุฉ) - ุงุฎุชูุงุฑู": 0.0  # ูุฃุฌู ุญุณุงุจ ุงูุชูููุฉ/ุงูููุฎุต ูุงุญููุง ูู ุฃุฑุฏุช
        })

    df_meta = pd.DataFrame(file_rows)
    st.info("ุนุฏูู ุงูููู ูู ุงูุฌุฏูู ุฃุฏูุงู ููู ููู ูุจู ุงูุจุฏุก.", icon="โ๏ธ")
    df_meta = st.data_editor(
        df_meta,
        use_container_width=True,
        hide_index=True,
        num_rows="fixed",
    )
else:
    df_meta = pd.DataFrame(columns=["index","ุงุณู ุงูููู","ุงุณู ุงูุดุฑูุฉ","ุงุณู ุงูููุธู","ุงููุธููุฉ","ุงูุฎุจุฑุฉ","ุงูุงุฎุชุตุงุต","ุงููุฏุฉ (ุฏูููุฉ) - ุงุฎุชูุงุฑู"])

# ====================== ุฏูุงู OpenAI ======================
def transcribe_file(client: OpenAI, file_obj, model_name: str) -> str:
    """
    ูุนูุฏ ูุตูุง ุนุฑุจููุง ูููุฑูุบูุง ูู ููู ุตูุชู ุจุงุณุชุฎุฏุงู OpenAI.
    """
    # ููุฑุฃ ุงูุจุงูุชุงุช ููุญูุงุธ ุนูู ุงูููู ููุงุณุชุฎุฏุงูุงุช ุงูุฃุฎุฑู ุฅู ูุฒู
    audio_bytes = file_obj.read()
    file_obj.seek(0)

    # ูุงุฌูุฉ ุงูุชูุฑูุบ
    result = client.audio.transcriptions.create(
        model=model_name,
        file=(file_obj.name, audio_bytes),
        language="ar",
        response_format="text",
        temperature=0.0
    )
    # result ูุต ุฎุงู ุนูุฏ response_format="text"
    return result.strip() if isinstance(result, str) else getattr(result, "text", "").strip()

def approx_tokens_from_text(text: str) -> int:
    # ุชูุฏูุฑ ุณุฑูุน: 1 token โ 4 ุฃุญุฑู ุนุฑุจูุฉ/ูุงุชูููุฉ ุชูุฑูุจูุง
    return max(1, math.ceil(len(text) / 4))

def analyze_text(client: OpenAI, text: str, model_name: str, temperature: float = 0.0) -> dict:
    """
    ููููุฏ ูุฎุฑุฌุงุช ุชุญููููุฉ ููุธููุฉ JSON: ููุฎุตุ ูุดุงุนุฑุ ููุงุฑุงุชุ ููุงุญุธุงุช/ุฃุนูุงู ุญูุฑุงุก.
    ูุณุชุฎุฏู JSON mode ูุถูุงู ูููู ุซุงุจุช.
    """
    sys = (
        "ุฃูุช ูุญูู ูุตูุต ุนุฑุจู. ุงุณุชุฎุฑุฌ ููุฎุตูุง ููุฌุฒูุงุ ุงููุดุงุนุฑ ุงูุนุงูุฉ (ููุฌุจ/ูุญุงูุฏ/ุณุงูุจ ูุน ุฏุฑุฌุฉ 0-1)ุ "
        "ูุงุฆูุฉ ููุงุฑุงุช ูุณุชูุชุฌุฉุ ูุฃู ููุงุญุธุงุช/ุฃุนูุงู ุญูุฑุงุก ููููุฉ. ุฃุนุฏ ุงููุชูุฌุฉ ูู JSON ููุท."
    )
    user = f"""
ุงููุต ุงูุนุฑุจู ุงูุชุงูู ูู ุชูุฑูุบ ูููุงุจูุฉ:
{text}
ุงุฑุฌุน JSON ุจุงููุฎุทุท:
{{
  "summary": "ููุฎุต ููุฌุฒ ุจุงูุนุฑุจูุฉ (3-6 ุฃุณุทุฑ)",
  "sentiment": {{"label": "ููุฌุจ|ูุญุงูุฏ|ุณุงูุจ", "score": 0.0}},
  "skills": ["ููุงุฑุฉ1","ููุงุฑุฉ2", "..."],
  "red_flags": ["ููุงุญุธุฉ", "..."]
}}
    """.strip()

    resp = client.responses.create(
        model=model_name,
        temperature=temperature,
        reasoning={"effort": "low"},
        response_format={"type": "json_object"},
        input=[
            {"role": "system", "content": sys},
            {"role": "user", "content": user}
        ]
    )

    # ุงุณุชุฎุฑุงุฌ ุงููุต ูู ุงููุฎุฑุฌุงุช
    content = ""
    if resp.output and len(resp.output) > 0 and hasattr(resp.output[0], "content") and len(resp.output[0].content) > 0:
        content = resp.output[0].content[0].text or ""
    else:
        # ุงุญุชูุงุท ููุงุฌูุงุช ูุฎุชููุฉ
        content = getattr(resp, "output_text", "") or ""

    try:
        data = json.loads(content) if content else {}
    except Exception:
        data = {"summary": "", "sentiment": {"label": "ูุญุงูุฏ", "score": 0.0}, "skills": [], "red_flags": []}
    return data

# ====================== ุฃุฒุฑุงุฑ ุงูุชูููุฐ ======================
col_run1, col_run2 = st.columns([1,1])
with col_run1:
    do_transcribe = st.button("โถ๏ธ ุจุฏุก ุงูุชูุฑูุบ + ุงูุชุญููู")
with col_run2:
    st.write("")

if do_transcribe:
    if not OPENAI_API_KEY:
        st.error("ุงูุฑุฌุงุก ุฅุฏุฎุงู ููุชุงุญ OpenAI API ุฃูููุง.", icon="๐ซ")
        st.stop()
    if uploaded_files is None or len(uploaded_files) == 0:
        st.warning("ุงูุฑุฌุงุก ุฑูุน ุงููููุงุช ุฃูููุง.", icon="๐")
        st.stop()

    client = OpenAI(api_key=OPENAI_API_KEY)

    # ุฎุฑูุฌ ููุงุฆู
    rows_result = []
    rows_analysis = []

    # ุชูุฏูู
    progress = st.progress(0)
    status = st.empty()

    # ูุจูู ุฎุฑูุทุฉ ูู ุงุณู ุงูููู โ ุจูุงูุงุชู ูู ุงูุฌุฏูู
    meta_map = {r["ุงุณู ุงูููู"]: r for _, r in df_meta.iterrows()} if not df_meta.empty else {}

    # ุชูุงููู ูุนููุฉ ุชูุฑูุจูุฉ (ููุฏูุฑ tokens ูู ุทูู ุงููุต)
    total_minutes = 0.0
    total_trx_cost = 0.0
    total_nlp_cost = 0.0

    for i, f in enumerate(uploaded_files, start=1):
        status.info(f"ุฌุงุฑู ูุนุงูุฌุฉ: {f.name} โฆ")

        # ุจูุงูุงุช ูุฐุง ุงูููู ูู ุงูุฌุฏูู
        meta = meta_map.get(f.name, {})
        company = meta.get("ุงุณู ุงูุดุฑูุฉ", "")
        employee = meta.get("ุงุณู ุงูููุธู", "")
        job_title = meta.get("ุงููุธููุฉ", "")
        experience = meta.get("ุงูุฎุจุฑุฉ", "")
        specialization = meta.get("ุงูุงุฎุชุตุงุต", "")
        minutes_opt = float(meta.get("ุงููุฏุฉ (ุฏูููุฉ) - ุงุฎุชูุงุฑู", 0.0) or 0.0)

        # 1) ุงูุชูุฑูุบ
        try:
            text = transcribe_file(client, f, trx_model)
        except Exception as e:
            text = f"ุฎุทุฃ ุฃุซูุงุก ุงูุชูุฑูุบ: {e}"

        # 2) ุงูุชุญููู
        analysis = {"summary": "", "sentiment": {"label": "", "score": 0.0}, "skills": [], "red_flags": []}
        if text and not text.startswith("ุฎุทุฃ ุฃุซูุงุก ุงูุชูุฑูุบ"):
            try:
                analysis = analyze_text(client, text, nlp_model, temperature=temperature)
            except Exception as e:
                analysis = {"summary": f"ุฎุทุฃ ุฃุซูุงุก ุงูุชุญููู: {e}", "sentiment": {"label": "ูุญุงูุฏ", "score": 0.0}, "skills": [], "red_flags": []}

        # 3) ุชุฌููุน ุตู ุงููุชุงุฆุฌ ุงูุนุฑุจูุฉ
        rows_result.append({
            "ุงุณู ุงูุดุฑูุฉ": company,
            "ุงุณู ุงูููุธู": employee,
            "ุงููุธููุฉ": job_title,
            "ุงูุฎุจุฑุฉ": experience,
            "ุงูุงุฎุชุตุงุต": specialization,
            "ุงูููุงุจูุฉ (ุงููุต ุงูููุฑุบ)": text
        })

        # 4) ุตู ุงูุชุญููู
        rows_analysis.append({
            "ุงุณู ุงูููู": f.name,
            "ููุฎุต": analysis.get("summary", ""),
            "ุงููุดุงุนุฑ - ุงูุชุตููู": (analysis.get("sentiment") or {}).get("label", ""),
            "ุงููุดุงุนุฑ - ุงูุฏุฑุฌุฉ": (analysis.get("sentiment") or {}).get("score", 0.0),
            "ุงูููุงุฑุงุช (ูุงุฆูุฉ)": ", ".join(analysis.get("skills") or []),
            "ุฃุนูุงู/ููุงุญุธุงุช": ", ".join(analysis.get("red_flags") or [])
        })

        # 5) ุชูุฏูุฑ ุงูุชูููุฉ ุงููุนููุฉ (ุชูุฑูุจูุฉ)
        # ุงูุชูุฑูุบ: ุฅู ุฃุฏุฎู ุงููุณุชุฎุฏู ูุฏุฉ ุงูููู ูุณุชุฎุฏููุงุ ูุฅูุง ูุง ูุญุณุจ ุชูุตููููุง (ูุฃููุง ูุง ูุณุชุฎุฑุฌ ุงููุฏุฉ ุฏูู ุญุฒู ุตูุช)
        if minutes_opt > 0:
            total_minutes += minutes_opt
        # ุชุญููู: ููุฏูุฑ tokens ูู ุทูู ุงููุต ุงูููุฑุบ
        t_in = approx_tokens_from_text(text) if text else 0
        # ููุชุฑุถ ูุฎุฑุฌุงุช ุงูุชุญููู ~ 500 tokens ููุนุฏู ุฅุฐุง ูู ูุณุชุทุน ููุงุณูุง
        t_out = max(500, approx_tokens_from_text(json.dumps(analysis)))
        total_nlp_cost += (t_in / 1000) * GPT_INPUT_PER_1K + (t_out / 1000) * GPT_OUTPUT_PER_1K

        progress.progress(i / len(uploaded_files))

    # ุชูููุฉ ุงูุชูุฑูุบ ุญุณุจ ุงูุฏูุงุฆู ุงูููุฏุฎูุฉ
    total_trx_cost = total_minutes * WHISPER_PER_MIN
    status.success("ุงูุชููุช ุงููุนุงูุฌุฉ โ")

    # ====================== ุนุฑุถ ุงูุฌุฏุงูู ======================
    df_results = pd.DataFrame(rows_result, columns=["ุงุณู ุงูุดุฑูุฉ","ุงุณู ุงูููุธู","ุงููุธููุฉ","ุงูุฎุจุฑุฉ","ุงูุงุฎุชุตุงุต","ุงูููุงุจูุฉ (ุงููุต ุงูููุฑุบ)"])
    df_analysis = pd.DataFrame(rows_analysis, columns=["ุงุณู ุงูููู","ููุฎุต","ุงููุดุงุนุฑ - ุงูุชุตููู","ุงููุดุงุนุฑ - ุงูุฏุฑุฌุฉ","ุงูููุงุฑุงุช (ูุงุฆูุฉ)","ุฃุนูุงู/ููุงุญุธุงุช"])

    st.subheader("๐ ุงููุชุงุฆุฌ")
    st.dataframe(df_results, use_container_width=True)

    st.subheader("๐ง ุงูุชุญูููุงุช")
    st.dataframe(df_analysis, use_container_width=True)

    # ====================== ุงูุชุตุฏูุฑ ุฅูู ุฅูุณู ======================
    excel_buffer = BytesIO()
    with pd.ExcelWriter(excel_buffer, engine="openpyxl") as writer:
        df_results.to_excel(writer, index=False, sheet_name="ุงููุชุงุฆุฌ")
        df_analysis.to_excel(writer, index=False, sheet_name="ุงูุชุญูููุงุช")
        # ูุฑูุฉ ููุฎูุต
        df_summary = pd.DataFrame([{
            "ุนุฏุฏ ุงููููุงุช": len(uploaded_files),
            "ูุฌููุน ุงูุฏูุงุฆู (ููุฏุฎู)": total_minutes,
            "ุชูููุฉ ุงูุชูุฑูุบ (ุชูุฏูุฑู $)": round(total_trx_cost, 4),
            "ุชูููุฉ ุงูุชุญููู (ุชูุฏูุฑู $)": round(total_nlp_cost, 4),
            "ุงูุฅุฌูุงูู (ุชูุฏูุฑู $)": round(total_trx_cost + total_nlp_cost, 4),
            "ูููุฌ ุงูุชูุฑูุบ": trx_model,
            "ูููุฐุฌ ุงูุชุญููู": nlp_model
        }])
        df_summary.to_excel(writer, index=False, sheet_name="ุงูููุฎูุต")
    excel_buffer.seek(0)

    now = datetime.now().strftime("%Y%m%d_%H%M%S")
    excel_name = f"ุชูุฑูุบ_ููููุงุช_ุชุญููู_{now}.xlsx"

    st.download_button(
        "โฌ๏ธ ุชุญููู ููู ุฅูุณู ุดุงูู",
        data=excel_buffer,
        file_name=excel_name,
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

# ====================== ููุงุญุธุงุช ======================
with st.expander("๐ก ููุงุญุธุงุช"):
    st.markdown(
        """
- ุงุณุชุฎุฏู **whisper-1** ููุชูุฑูุบ ูุชูุงุฏู ูุดุงูู ุงูุชุจุนูุงุช.  
- ุฃุฏุฎู ูุฏุฉ ูู ููู (ุงุฎุชูุงุฑู) ูู ุงูุฌุฏูู ูุชุญุตู ุนูู **ุชูููุฉ ุชูุฑูุบ ุฃุฏู** ูู ูุฑูุฉ ุงูููุฎูุต.  
- ุงูุชุญููู ูุณุชุฎุฏู **JSON mode** ูุงุณุชุฎุฑุงุฌ ููุฎุต/ูุดุงุนุฑ/ููุงุฑุงุช/ููุงุญุธุงุช ุจุงูุนุฑุจูุฉ.  
- ูุง ุชุญูุธ ุงูููุชุงุญ ูู ุงูููุฏ ุฃู GitHub โ ุงุณุชุนูู **Secrets** ูู Streamlit Cloud.
        """
    )
